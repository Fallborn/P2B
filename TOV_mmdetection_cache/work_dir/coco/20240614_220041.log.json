{"env_info": "sys.platform: linux\nPython: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]\nCUDA available: True\nGPU 0,1,2,3,4,5,6,7: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda-12.0\nNVCC: Build cuda_12.0.r12.0/compiler.31968024_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.0\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.0.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.0\nOpenCV: 4.8.1\nMMCV: 1.3.3\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.0\nMMDetection: 2.13.0+c820f32", "config": "checkpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '../TOV_mmdetection_cache/work_dir/coco/pre_trained/P2B.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnorm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\ndebug = False\nnum_stages = 2\nmodel = dict(\n    type='P2BNet',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4,\n        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),\n    roi_head=dict(\n        type='P2BHead',\n        num_stages=2,\n        top_k=7,\n        with_atten=False,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCInstanceMILHead',\n            num_stages=2,\n            with_loss_pseudo=False,\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=6,\n            num_ref_fcs=0,\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0.0, 0.0, 0.0, 0.0],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=True,\n            loss_type='MIL',\n            loss_mil1=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='binary_cross_entropy'),\n            loss_mil2=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='gfocal_loss'))),\n    train_cfg=dict(\n        base_proposal=dict(\n            base_scales=[4, 8, 16, 32, 64, 128],\n            base_ratios=[\n                0.3333333333333333, 0.5, 0.6666666666666666, 1.0, 1.5, 2.0, 3.0\n            ],\n            shake_ratio=None,\n            cut_mode='symmetry',\n            gen_num_neg=0),\n        fine_proposal=dict(\n            gen_proposal_mode='fix_gen',\n            cut_mode=None,\n            shake_ratio=[0.1],\n            base_ratios=[1, 1.2, 1.3, 0.8, 0.7],\n            iou_thr=0.3,\n            gen_num_neg=3500),\n        rcnn=None),\n    test_cfg=dict(rpn=None, rcnn=None))\ndataset_type = 'CocoFmtDataset'\ndata_root = 'data/coco/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='Resize',\n        img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                   (2000, 1000), (2000, 1200)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_true_bboxes'\n        ])\n]\ntest_scale = 1200\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2000, 1200),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_anns_id', 'gt_true_bboxes'\n                ])\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=1,\n    shuffle=None,\n    train=dict(\n        type='CocoFmtDataset',\n        ann_file='data/coco/annotations_qc_pt/instances_train2017_coarse.json',\n        img_prefix='data/coco/images/train/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='Resize',\n                img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                           (2000, 1000), (2000, 1200)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_true_bboxes'\n                ])\n        ]),\n    val=dict(\n        samples_per_gpu=16,\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/lxz/P2BNet/TOV_mmdetection/data/coco/annotations/instances_train.json',\n        img_prefix='data/coco/images/train',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ],\n        test_mode=False),\n    test=dict(\n        samples_per_gpu=16,\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/lxz/P2BNet/TOV_mmdetection/data/coco/annotations/instances_train.json',\n        img_prefix='data/coco/images/train/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ],\n        test_mode=False))\ncheck = dict(stop_while_nan=False)\noptimizer = dict(\n    type='AdamW',\n    lr=5e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            absolute_pos_embed=dict(decay_mult=0.0),\n            relative_position_bias_table=dict(decay_mult=0.0),\n            norm=dict(decay_mult=0.0))))\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=24)\nwork_dir = '../TOV_mmdetection_cache/work_dir/coco/'\nevaluation = dict(\n    interval=2,\n    metric='bbox',\n    save_result_file=\n    '../TOV_mmdetection_cache/work_dir/coco/_1200_latest_result.json',\n    do_first_eval=False,\n    do_final_eval=True)\ngpu_ids = [5]\n", "seed": null, "exp_name": "P2BNet_r50_fpn_1x_coco_ms.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 17861, "data_time": 0.08022, "stage0_loss_instance_mil": 0.72874, "stage0_bag_acc": 15.85, "stage0_mean_ious": 0.34548, "stage0_s": 0.0, "stage0_m": 0.03261, "stage0_l": 0.2169, "stage0_h": 0.36461, "stage1_loss_instance_mil": 0.16308, "stage1_bag_acc": 23.67218, "stage1_neg_loss": 0.00084, "stage1_mean_ious": 0.34228, "stage1_s": 0.0, "stage1_m": 0.03148, "stage1_l": 0.21327, "stage1_h": 0.3624, "loss": 0.89266, "grad_norm": 3.30668, "time": 1.77204}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 1e-05, "memory": 17861, "data_time": 0.02882, "stage0_loss_instance_mil": 0.61077, "stage0_bag_acc": 39.76273, "stage0_mean_ious": 0.37574, "stage0_s": 0.0, "stage0_m": 0.01627, "stage0_l": 0.24887, "stage0_h": 0.38692, "stage1_loss_instance_mil": 0.23125, "stage1_bag_acc": 19.79838, "stage1_neg_loss": 0.00329, "stage1_mean_ious": 0.36464, "stage1_s": 0.0, "stage1_m": 0.01614, "stage1_l": 0.23513, "stage1_h": 0.37614, "loss": 0.84531, "grad_norm": 3.5912, "time": 1.70878}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 1e-05, "memory": 17861, "data_time": 0.02904, "stage0_loss_instance_mil": 0.29219, "stage0_bag_acc": 82.12713, "stage0_mean_ious": 0.3543, "stage0_s": 0.0, "stage0_m": 0.04731, "stage0_l": 0.23203, "stage0_h": 0.37051, "stage1_loss_instance_mil": 0.32844, "stage1_bag_acc": 73.60942, "stage1_neg_loss": 0.06627, "stage1_mean_ious": 0.34906, "stage1_s": 0.0, "stage1_m": 0.04321, "stage1_l": 0.21258, "stage1_h": 0.36736, "loss": 0.68691, "grad_norm": 10.70503, "time": 1.69688}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 2e-05, "memory": 17861, "data_time": 0.08348, "stage0_loss_instance_mil": 0.09328, "stage0_bag_acc": 94.80505, "stage0_mean_ious": 0.2681, "stage0_s": 0.0, "stage0_m": 0.03198, "stage0_l": 0.15461, "stage0_h": 0.28045, "stage1_loss_instance_mil": 0.36766, "stage1_bag_acc": 96.8281, "stage1_neg_loss": 0.08646, "stage1_mean_ious": 0.26186, "stage1_s": 0.0, "stage1_m": 0.0265, "stage1_l": 0.14616, "stage1_h": 0.27479, "loss": 0.54739, "grad_norm": 11.35655, "time": 1.75941}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 3e-05, "memory": 17861, "data_time": 0.03433, "stage0_loss_instance_mil": 0.06881, "stage0_bag_acc": 96.41444, "stage0_mean_ious": 0.26024, "stage0_s": 0.0, "stage0_m": 0.05143, "stage0_l": 0.13798, "stage0_h": 0.27051, "stage1_loss_instance_mil": 0.35842, "stage1_bag_acc": 97.14493, "stage1_neg_loss": 0.09804, "stage1_mean_ious": 0.24249, "stage1_s": 0.0, "stage1_m": 0.04476, "stage1_l": 0.12152, "stage1_h": 0.25347, "loss": 0.52528, "grad_norm": 15.1358, "time": 1.72035}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 3e-05, "memory": 17861, "data_time": 0.03336, "stage0_loss_instance_mil": 0.0434, "stage0_bag_acc": 97.47401, "stage0_mean_ious": 0.29215, "stage0_s": 0.0, "stage0_m": 0.06726, "stage0_l": 0.1209, "stage0_h": 0.31118, "stage1_loss_instance_mil": 0.34789, "stage1_bag_acc": 98.36367, "stage1_neg_loss": 0.09138, "stage1_mean_ious": 0.28085, "stage1_s": 0.0, "stage1_m": 0.05885, "stage1_l": 0.10667, "stage1_h": 0.30138, "loss": 0.48267, "grad_norm": 16.66183, "time": 1.71753}
{"mode": "val", "epoch": 2, "iter": 180, "lr": 4e-05, "eval_iter_num": 90, "bbox_mAP": 0.048, "bbox_mAP_50": 0.204, "bbox_mAP_75": 0.077, "bbox_mAP_s": 0.016, "bbox_mAP_m": 0.005, "bbox_mAP_l": 0.001, "bbox_mAP_copypaste": "0.048 0.204 0.077 0.016 0.005 0.001"}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 4e-05, "memory": 17861, "data_time": 0.08052, "stage0_loss_instance_mil": 0.05243, "stage0_bag_acc": 96.93881, "stage0_mean_ious": 0.30986, "stage0_s": 0.0, "stage0_m": 0.034, "stage0_l": 0.10802, "stage0_h": 0.33363, "stage1_loss_instance_mil": 0.29656, "stage1_bag_acc": 98.57207, "stage1_neg_loss": 0.08174, "stage1_mean_ious": 0.29108, "stage1_s": 0.0, "stage1_m": 0.02453, "stage1_l": 0.09327, "stage1_h": 0.31542, "loss": 0.43074, "grad_norm": 14.41942, "time": 1.78478}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 5e-05, "memory": 17861, "data_time": 0.02738, "stage0_loss_instance_mil": 0.04586, "stage0_bag_acc": 96.70382, "stage0_mean_ious": 0.28691, "stage0_s": 0.0, "stage0_m": 0.03163, "stage0_l": 0.11188, "stage0_h": 0.30692, "stage1_loss_instance_mil": 0.27786, "stage1_bag_acc": 97.47634, "stage1_neg_loss": 0.10212, "stage1_mean_ious": 0.26257, "stage1_s": 0.0, "stage1_m": 0.02093, "stage1_l": 0.0921, "stage1_h": 0.28357, "loss": 0.42583, "grad_norm": 18.88977, "time": 1.65909}
{"mode": "train", "epoch": 3, "iter": 150, "lr": 5e-05, "memory": 17861, "data_time": 0.02807, "stage0_loss_instance_mil": 0.05795, "stage0_bag_acc": 95.85887, "stage0_mean_ious": 0.26465, "stage0_s": 0.0, "stage0_m": 0.06576, "stage0_l": 0.1117, "stage0_h": 0.2814, "stage1_loss_instance_mil": 0.25125, "stage1_bag_acc": 98.19851, "stage1_n
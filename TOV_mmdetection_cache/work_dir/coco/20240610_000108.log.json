{"env_info": "sys.platform: linux\nPython: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]\nCUDA available: True\nGPU 0,1,2,3,4,5,6,7: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda-12.0\nNVCC: Build cuda_12.0.r12.0/compiler.31968024_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.0\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.0.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.0\nOpenCV: 4.8.1\nMMCV: 1.3.3\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.0\nMMDetection: 2.13.0+c820f32", "config": "checkpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = '../TOV_mmdetection_cache/work_dir/coco/pre_trained/P2B.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnorm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\ndebug = False\nnum_stages = 2\nmodel = dict(\n    type='P2BNet',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4,\n        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True)),\n    roi_head=dict(\n        type='P2BHead',\n        num_stages=2,\n        top_k=7,\n        with_atten=False,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCInstanceMILHead',\n            num_stages=2,\n            with_loss_pseudo=False,\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=6,\n            num_ref_fcs=0,\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0.0, 0.0, 0.0, 0.0],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=True,\n            loss_type='MIL',\n            loss_mil1=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='binary_cross_entropy'),\n            loss_mil2=dict(\n                type='MILLoss',\n                binary_ins=False,\n                loss_weight=0.25,\n                loss_type='gfocal_loss'))),\n    train_cfg=dict(\n        base_proposal=dict(\n            base_scales=[4, 8, 16, 32, 64, 128],\n            base_ratios=[\n                0.3333333333333333, 0.5, 0.6666666666666666, 1.0, 1.5, 2.0, 3.0\n            ],\n            shake_ratio=None,\n            cut_mode='symmetry',\n            gen_num_neg=0),\n        fine_proposal=dict(\n            gen_proposal_mode='fix_gen',\n            cut_mode=None,\n            shake_ratio=[0.1],\n            base_ratios=[1, 1.2, 1.3, 0.8, 0.7],\n            iou_thr=0.3,\n            gen_num_neg=3500),\n        rcnn=None),\n    test_cfg=dict(rpn=None, rcnn=None))\ndataset_type = 'CocoFmtDataset'\ndata_root = 'data/coco/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='Resize',\n        img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                   (2000, 1000), (2000, 1200)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=[\n            'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n            'gt_true_bboxes'\n        ])\n]\ntest_scale = 1200\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2000, 1200),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_anns_id', 'gt_true_bboxes'\n                ])\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=1,\n    shuffle=None,\n    train=dict(\n        type='CocoFmtDataset',\n        ann_file='data/coco/annotations_qc_pt/instances_train2017_coarse.json',\n        img_prefix='data/coco/images/train/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='Resize',\n                img_scale=[(2000, 480), (2000, 576), (2000, 688), (2000, 864),\n                           (2000, 1000), (2000, 1200)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=[\n                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n                    'gt_true_bboxes'\n                ])\n        ]),\n    val=dict(\n        samples_per_gpu=16,\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/lxz/P2BNet/TOV_mmdetection/data/coco/annotations/instances_train.json',\n        img_prefix='data/coco/images/train',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ],\n        test_mode=False),\n    test=dict(\n        samples_per_gpu=16,\n        type='CocoFmtDataset',\n        ann_file=\n        '/home/lxz/P2BNet/TOV_mmdetection/data/coco/annotations/instances_train.json',\n        img_prefix='data/coco/images/train/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2000, 1200),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='DefaultFormatBundle'),\n                    dict(\n                        type='Collect',\n                        keys=[\n                            'img', 'gt_bboxes', 'gt_labels',\n                            'gt_bboxes_ignore', 'gt_anns_id', 'gt_true_bboxes'\n                        ])\n                ])\n        ],\n        test_mode=False))\ncheck = dict(stop_while_nan=False)\noptimizer = dict(\n    type='AdamW',\n    lr=5e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            absolute_pos_embed=dict(decay_mult=0.0),\n            relative_position_bias_table=dict(decay_mult=0.0),\n            norm=dict(decay_mult=0.0))))\noptimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\nrunner = dict(type='EpochBasedRunner', max_epochs=24)\nwork_dir = '../TOV_mmdetection_cache/work_dir/coco/'\nevaluation = dict(\n    interval=2,\n    metric='bbox',\n    save_result_file=\n    '../TOV_mmdetection_cache/work_dir/coco/_1200_latest_result.json',\n    do_first_eval=False,\n    do_final_eval=True)\ngpu_ids = [5]\n", "seed": null, "exp_name": "P2BNet_r50_fpn_1x_coco_ms.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 17825, "data_time": 0.07795, "stage0_loss_instance_mil": 0.72983, "stage0_bag_acc": 10.29964, "stage0_mean_ious": 0.33237, "stage0_s": 0.00136, "stage0_m": 0.03527, "stage0_l": 0.19484, "stage0_h": 0.34841, "stage1_loss_instance_mil": 0.15646, "stage1_bag_acc": 15.49955, "stage1_neg_loss": 0.00139, "stage1_mean_ious": 0.33225, "stage1_s": 0.00154, "stage1_m": 0.03922, "stage1_l": 0.19197, "stage1_h": 0.34797, "loss": 0.88767, "grad_norm": 3.39434, "time": 1.75928}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 1e-05, "memory": 17825, "data_time": 0.02707, "stage0_loss_instance_mil": 0.5619, "stage0_bag_acc": 64.6437, "stage0_mean_ious": 0.37535, "stage0_s": 0.0, "stage0_m": 0.04242, "stage0_l": 0.21768, "stage0_h": 0.39278, "stage1_loss_instance_mil": 0.24469, "stage1_bag_acc": 28.67298, "stage1_neg_loss": 0.00906, "stage1_mean_ious": 0.36342, "stage1_s": 0.0, "stage1_m": 0.03784, "stage1_l": 0.20363, "stage1_h": 0.38192, "loss": 0.81564, "grad_norm": 4.58401, "time": 1.72768}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 1e-05, "memory": 17825, "data_time": 0.02837, "stage0_loss_instance_mil": 0.21502, "stage0_bag_acc": 91.44709, "stage0_mean_ious": 0.42976, "stage0_s": 0.0, "stage0_m": 0.0325, "stage0_l": 0.23541, "stage0_h": 0.45109, "stage1_loss_instance_mil": 0.36212, "stage1_bag_acc": 91.24261, "stage1_neg_loss": 0.06901, "stage1_mean_ious": 0.40481, "stage1_s": 0.0, "stage1_m": 0.03861, "stage1_l": 0.22365, "stage1_h": 0.42366, "loss": 0.64614, "grad_norm": 9.55261, "time": 1.7361}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 2e-05, "memory": 17825, "data_time": 0.07792, "stage0_loss_instance_mil": 0.0661, "stage0_bag_acc": 96.46323, "stage0_mean_ious": 0.37455, "stage0_s": 0.0, "stage0_m": 0.031, "stage0_l": 0.20409, "stage0_h": 0.39523, "stage1_loss_instance_mil": 0.33673, "stage1_bag_acc": 98.03789, "stage1_neg_loss": 0.08914, "stage1_mean_ious": 0.34512, "stage1_s": 0.0, "stage1_m": 0.02751, "stage1_l": 0.18609, "stage1_h": 0.365, "loss": 0.49197, "grad_norm": 11.41426, "time": 1.77219}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 3e-05, "memory": 17825, "data_time": 0.02802, "stage0_loss_instance_mil": 0.0564, "stage0_bag_acc": 96.39427, "stage0_mean_ious": 0.39131, "stage0_s": 0.0, "stage0_m": 0.05592, "stage0_l": 0.15171, "stage0_h": 0.41747, "stage1_loss_instance_mil": 0.30408, "stage1_bag_acc": 98.14009, "stage1_neg_loss": 0.0877, "stage1_mean_ious": 0.3632, "stage1_s": 0.0, "stage1_m": 0.04635, "stage1_l": 0.13372, "stage1_h": 0.38835, "loss": 0.44819, "grad_norm": 11.82474, "time": 1.70798}
{"mode": "train", "epoch": 2, "iter": 150, "lr": 3e-05, "memory": 17825, "data_time": 0.0264, "stage0_loss_instance_mil": 0.04366, "stage0_bag_acc": 97.93684, "stage0_mean_ious": 0.36809, "stage0_s": 0.0, "stage0_m": 0.02865, "stage0_l": 0.16534, "stage0_h": 0.39664, "stage1_loss_instance_mil": 0.31306, "stage1_bag_acc": 98.39703, "stage1_neg_loss": 0.08016, "stage1_mean_ious": 0.34337, "stage1_s": 0.0, "stage1_m": 0.02157, "stage1_l": 0.13848, "stage1_h": 0.37227, "loss": 0.43688, "grad_norm": 13.52291, "time": 1.70865}
{"mode": "val", "epoch": 2, "iter": 180, "lr": 4e-05, "eval_iter_num": 90, "bbox_mAP": 0.067, "bbox_mAP_50": 0.217, "bbox_mAP_75": 0.122, "bbox_mAP_s": 0.047, "bbox_mAP_m": 0.024, "bbox_mAP_l": 0.006, "bbox_mAP_copypaste": "0.067 0.217 0.122 0.047 0.024 0.006"}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 4e-05, "memory": 17825, "data_time": 0.08453, "stage0_loss_instance_mil": 0.03641, "stage0_bag_acc": 98.08102, "stage0_mean_ious": 0.37587, "stage0_s": 0.0, "stage0_m": 0.03257, "stage0_l": 0.13819, "stage0_h": 0.39525, "stage1_loss_instance_mil": 0.25544, "stage1_bag_acc": 99.12669, "stage1_neg_loss": 0.08427, "stage1_mean_ious": 0.34031, "stage1_s": 0.0, "stage1_m": 0.02614, "stage1_l": 0.12471, "stage1_h": 0.35809, "loss": 0.37612, "grad_norm": 14.96331, "time": 1.76412}
